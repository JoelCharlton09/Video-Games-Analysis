{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this notebook we explore and prepare the dataset being used for this analysis. The data preparation tasks which will be considered are:\n",
    "\n",
    "1. Checking for any duplicate rows and removing them.\n",
    "2. Search for any outliers/incorrect data entries.\n",
    "3. How best to deal with any missing values in the data.\n",
    "4. Perform type conversions.\n",
    "5. Feature scaling.\n",
    "\n",
    "All of the above tasks will be completed in this notebook. This will ensure that the data is in the correct format and is ready to be used within the analysis. We begin with the imports required for the data preprocessing and looking at the first few rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.49</td>\n",
       "      <td>29.02</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.46</td>\n",
       "      <td>82.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.75</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.96</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      Name Platform    Year         Genre Publisher  \\\n",
       "0     1                Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
       "1     2         Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
       "2     3            Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
       "3     4         Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
       "4     5  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
       "0     41.49     29.02      3.77         8.46         82.74  \n",
       "1     29.08      3.58      6.81         0.77         40.24  \n",
       "2     15.85     12.88      3.79         3.31         35.82  \n",
       "3     15.75     11.01      3.28         2.96         33.00  \n",
       "4     11.27      8.89     10.22         1.00         31.37  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and look at the first few rows\n",
    "raw = pd.read_csv(\"../data/raw/vgsales.csv\")\n",
    "raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is in order of which game is the most popular on a global level, hence the three most popular games are Wii Sports, Super Mario Bros and Mario Kart Wii. These are all games published by Nintendo and it is clear that the top 5 most popular games are all published by Nintendo.\n",
    "\n",
    "We can now commence with the data preprocessing tasks outlined above. First we check for any duplicate rows and delete them if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated rows.\n"
     ]
    }
   ],
   "source": [
    "# Check for any duplicated rows and delete them\n",
    "num_duplicates = raw.duplicated().sum()\n",
    "print(f\"There are {num_duplicates} duplicated rows.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there isn't any duplicated data, our first preprocessing task is complete. Next we search for outliers and any incorrect data entries. We begin with the latter of these. An incorrect data entry would be when the year is greater than 2016. This is due to the fact that the data has not been updated since that year and hence it would not make sense for any games to have a relesase year after that date. When identified, the actual release year will be found and the incorrect entries will be updated with the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>5959</td>\n",
       "      <td>Imagine: Makeup Artist</td>\n",
       "      <td>DS</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>Ubisoft</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>14393</td>\n",
       "      <td>Phantasy Star Online 2 Episode 4: Deluxe Package</td>\n",
       "      <td>PS4</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Sega</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16241</th>\n",
       "      <td>16244</td>\n",
       "      <td>Phantasy Star Online 2 Episode 4: Deluxe Package</td>\n",
       "      <td>PSV</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Sega</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16438</th>\n",
       "      <td>16441</td>\n",
       "      <td>Brothers Conflict: Precious Baby</td>\n",
       "      <td>PSV</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Idea Factory</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank                                              Name Platform  \\\n",
       "5957    5959                            Imagine: Makeup Artist       DS   \n",
       "14390  14393  Phantasy Star Online 2 Episode 4: Deluxe Package      PS4   \n",
       "16241  16244  Phantasy Star Online 2 Episode 4: Deluxe Package      PSV   \n",
       "16438  16441                  Brothers Conflict: Precious Baby      PSV   \n",
       "\n",
       "         Year         Genre     Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "5957   2020.0    Simulation       Ubisoft      0.27       0.0      0.00   \n",
       "14390  2017.0  Role-Playing          Sega      0.00       0.0      0.03   \n",
       "16241  2017.0  Role-Playing          Sega      0.00       0.0      0.01   \n",
       "16438  2017.0        Action  Idea Factory      0.00       0.0      0.01   \n",
       "\n",
       "       Other_Sales  Global_Sales  \n",
       "5957          0.02          0.29  \n",
       "14390         0.00          0.03  \n",
       "16241         0.00          0.01  \n",
       "16438         0.00          0.01  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify any incorrect entries for the Year\n",
    "raw[raw[\"Year\"] > 2016]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After researching, it was found that these games were released on the specified consoles in the years 2009, 2016, 2013 and 2016 respectively. These are updated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All years are up to date!\n"
     ]
    }
   ],
   "source": [
    "# Updating the Year with the correct values\n",
    "updates = {5957:2009, 14390:2016, 16241:2013, 16438:2016}\n",
    "for i in updates.keys():\n",
    "    raw.iloc[i,3] = updates[i]\n",
    "    \n",
    "if raw[raw[\"Year\"] > 2016].any().sum() == 0:\n",
    "    print(\"All years are up to date!\")\n",
    "else:\n",
    "    print(\"There are still incorrect entries.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with the next part of the task, we will determine if any outliers exist in the data. To do this we will examine some summary statistics of the numeric sales features that are in the data set. An alternative way to do this would be to make either box plots or histograms. However, this will not be done here due to the nature of the dataset. It appears a large percentage of the video games didn't have sales greater than 1 million, hence the figures will not be the most informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264667</td>\n",
       "      <td>0.146652</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>0.537441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.816683</td>\n",
       "      <td>0.505351</td>\n",
       "      <td>0.309291</td>\n",
       "      <td>0.188588</td>\n",
       "      <td>1.555028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.490000</td>\n",
       "      <td>29.020000</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.570000</td>\n",
       "      <td>82.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NA_Sales      EU_Sales      JP_Sales   Other_Sales  Global_Sales\n",
       "count  16598.000000  16598.000000  16598.000000  16598.000000  16598.000000\n",
       "mean       0.264667      0.146652      0.077782      0.048063      0.537441\n",
       "std        0.816683      0.505351      0.309291      0.188588      1.555028\n",
       "min        0.000000      0.000000      0.000000      0.000000      0.010000\n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.060000\n",
       "50%        0.080000      0.020000      0.000000      0.010000      0.170000\n",
       "75%        0.240000      0.110000      0.040000      0.040000      0.470000\n",
       "max       41.490000     29.020000     10.220000     10.570000     82.740000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of the numeric sales features\n",
    "numeric_sales_features = [\"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"Global_Sales\"]\n",
    "sales_data = raw[numeric_sales_features]\n",
    "sales_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the mean and standard deviation values, it looks as though all of the max values for the sales could be outliers. However, the max value for NA_Sales, EU_Sale and Global_sales is Wii Sports which is ranked the most popular game in the dataset. Since this is the most popular game in the dataset, by a significant amount, this will not be removed from the data. The max for JP_Sales is Pokemon Red/Pokemon Blue which were the first ever games released in a hugely popular franchise. Again, this will not be ignored. Finally, the game with the max sales for Other_Sales is Grand Theft Auto: San Andreas which is also part of another popular franchise. This will not be removed from the dataset either.\n",
    "\n",
    "It is always possible that other outliers lie within the dataset but, as mentioned, due to the nature of the dataset it is difficult to produce any meaningful visualisations to search for these. Other methods such as converting values to z scores could be considered, however since the dataset is fairly small we will stop the search for outliers and conclude that there aren't any in the data.\n",
    "\n",
    "The next task is to search for any missing values in the data, this is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank              0\n",
       "Name              0\n",
       "Platform          0\n",
       "Year            271\n",
       "Genre             0\n",
       "Publisher        58\n",
       "NA_Sales          0\n",
       "EU_Sales          0\n",
       "JP_Sales          0\n",
       "Other_Sales       0\n",
       "Global_Sales      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for where the missing values are\n",
    "raw.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only type which looks wrong is the Year feature. This is turned into an integer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Change Year to an integer value instead of a decimal\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m raw[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m raw[\u001b[39m'\u001b[39;49m\u001b[39mYear\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m raw\u001b[39m.\u001b[39minfo()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/internals/managers.py:450\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 450\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:140\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot astype a timedelta from [\u001b[39m\u001b[39m{\u001b[39;00marr\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m] to [\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[1;32m    142\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m     \u001b[39m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(values)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    183\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[39m# GH#45151\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (values \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "# Change Year to an integer value instead of a decimal\n",
    "raw['Year'] = raw['Year'].astype('int')\n",
    "raw.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there are missing values for both the Year and Publisher features. Year has 271 missing values whilst Publisher has 58. Another thing to note is that this dataset has not been updated since 2016. This means we need to check for any incorrect entries in the dataset and update them with the correct values. We begin by focusing on the Year feature.\n",
    "\n",
    "In the step below, all missing values for the Year feature are imputed using the median year value. The median is chosen as this is a more robust metric of location than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values for the Year feature.\n"
     ]
    }
   ],
   "source": [
    "# Imputing the missing Year value with the median year\n",
    "year_median = raw[\"Year\"].median(skipna=True)\n",
    "raw[\"Year\"] = raw[\"Year\"].fillna(year_median)\n",
    "missing_vals = raw[\"Year\"].isnull().sum()\n",
    "\n",
    "print(f\"There are {missing_vals} missing values for the Year feature.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search for any incorrect entries for the Year. These are any values in the dataset where Year is greater than 2016. When identified, the actual release year will be found and the incorrect entries will be updated with the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>5959</td>\n",
       "      <td>Imagine: Makeup Artist</td>\n",
       "      <td>DS</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>Ubisoft</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>14393</td>\n",
       "      <td>Phantasy Star Online 2 Episode 4: Deluxe Package</td>\n",
       "      <td>PS4</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Sega</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16241</th>\n",
       "      <td>16244</td>\n",
       "      <td>Phantasy Star Online 2 Episode 4: Deluxe Package</td>\n",
       "      <td>PSV</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Sega</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16438</th>\n",
       "      <td>16441</td>\n",
       "      <td>Brothers Conflict: Precious Baby</td>\n",
       "      <td>PSV</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Idea Factory</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank                                              Name Platform  \\\n",
       "5957    5959                            Imagine: Makeup Artist       DS   \n",
       "14390  14393  Phantasy Star Online 2 Episode 4: Deluxe Package      PS4   \n",
       "16241  16244  Phantasy Star Online 2 Episode 4: Deluxe Package      PSV   \n",
       "16438  16441                  Brothers Conflict: Precious Baby      PSV   \n",
       "\n",
       "         Year         Genre     Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "5957   2020.0    Simulation       Ubisoft      0.27       0.0      0.00   \n",
       "14390  2017.0  Role-Playing          Sega      0.00       0.0      0.03   \n",
       "16241  2017.0  Role-Playing          Sega      0.00       0.0      0.01   \n",
       "16438  2017.0        Action  Idea Factory      0.00       0.0      0.01   \n",
       "\n",
       "       Other_Sales  Global_Sales  \n",
       "5957          0.02          0.29  \n",
       "14390         0.00          0.03  \n",
       "16241         0.00          0.01  \n",
       "16438         0.00          0.01  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify any incorrect entries for the Year\n",
    "raw[raw[\"Year\"] > 2016]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year is now correct for each video game and there are no longer any missing values for this feature. This is now complete and does not require anymore preprocessing. \n",
    "\n",
    "Next the Publisher feature will be prepared for analysis. Only a small percentage of values are missing for this feature, also this feature will not play much of a role within the analysis being completed. For these reasons, any missing values will be imputed with the value \"Unknown\". An alternative to this would be to remove the rows containing missing values. However, imputing the missing values with \"Unknown\" means we get to keep more data and can perform a more granular analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute \"Unknown\" for missing values in the Publisher feature\n",
    "raw['Publisher'] = raw['Publisher'].fillna('Unknown')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All missing values have now been changed and the data is complete. \n",
    "\n",
    "Next we investigate each data type and update any which are incorrect."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude the data exploration by looking at some basic descriptive statistics of the numeric features in the dataset. These can be seen below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the average year that a video game was released in the dataset is 2006 which suggests that the games in the dataset are fairly old. We can also see that the region where average sales are the highest is North America, this is followed by Europe but the difference between these averages are rather significant. Globally, on average, a video game has approximately 537,000 sales. \n",
    "\n",
    "The oldest game in the dataset was released in 1980 and the latest game released was in 2016. This means we are investigating a variety of different video games from different periods in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.to_csv(\"../data/processed/vgsales_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
