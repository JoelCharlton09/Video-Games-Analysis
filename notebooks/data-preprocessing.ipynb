{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this notebook we explore and prepare the dataset being used for this analysis. The data preparation tasks which will be considered are:\n",
    "\n",
    "1. Checking for any duplicate rows and removing them.\n",
    "2. Search for any outliers/incorrect data entries.\n",
    "3. How best to deal with any missing values in the data.\n",
    "4. Perform type conversions.\n",
    "\n",
    "All of the above tasks will be completed in this notebook. This will ensure that the data is in the correct format and is ready to be used within the analysis. We begin with the imports required for the data preprocessing and looking at the first few rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.49</td>\n",
       "      <td>29.02</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.46</td>\n",
       "      <td>82.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.75</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.96</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      Name Platform    Year         Genre Publisher  \\\n",
       "0     1                Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
       "1     2         Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
       "2     3            Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
       "3     4         Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
       "4     5  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
       "0     41.49     29.02      3.77         8.46         82.74  \n",
       "1     29.08      3.58      6.81         0.77         40.24  \n",
       "2     15.85     12.88      3.79         3.31         35.82  \n",
       "3     15.75     11.01      3.28         2.96         33.00  \n",
       "4     11.27      8.89     10.22         1.00         31.37  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and look at the first few rows\n",
    "raw = pd.read_csv(\"../data/raw/vgsales.csv\")\n",
    "raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is in order of which game is the most popular on a global level, hence the three most popular games are Wii Sports, Super Mario Bros and Mario Kart Wii. These are all games published by Nintendo and it is clear that the top 5 most popular games are all published by Nintendo.\n",
    "\n",
    "We can now commence with the data preprocessing tasks outlined above. First we check for any duplicate rows and delete them if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated rows.\n"
     ]
    }
   ],
   "source": [
    "# Check for any duplicated rows and delete them\n",
    "num_duplicates = raw.duplicated().sum()\n",
    "print(f\"There are {num_duplicates} duplicated rows.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there isn't any duplicated data, our first preprocessing task is complete. Next we search for outliers and any incorrect data entries. We begin with the latter of these. An incorrect data entry would be when the year is greater than 2016. This is due to the fact that the data has not been updated since that year and hence it would not make sense for any games to have a relesase year after that date. When identified, the actual release year will be found and the incorrect entries will be updated with the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>5959</td>\n",
       "      <td>Imagine: Makeup Artist</td>\n",
       "      <td>DS</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>Ubisoft</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>14393</td>\n",
       "      <td>Phantasy Star Online 2 Episode 4: Deluxe Package</td>\n",
       "      <td>PS4</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Sega</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16241</th>\n",
       "      <td>16244</td>\n",
       "      <td>Phantasy Star Online 2 Episode 4: Deluxe Package</td>\n",
       "      <td>PSV</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Sega</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16438</th>\n",
       "      <td>16441</td>\n",
       "      <td>Brothers Conflict: Precious Baby</td>\n",
       "      <td>PSV</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Idea Factory</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank                                              Name Platform  \\\n",
       "5957    5959                            Imagine: Makeup Artist       DS   \n",
       "14390  14393  Phantasy Star Online 2 Episode 4: Deluxe Package      PS4   \n",
       "16241  16244  Phantasy Star Online 2 Episode 4: Deluxe Package      PSV   \n",
       "16438  16441                  Brothers Conflict: Precious Baby      PSV   \n",
       "\n",
       "         Year         Genre     Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "5957   2020.0    Simulation       Ubisoft      0.27       0.0      0.00   \n",
       "14390  2017.0  Role-Playing          Sega      0.00       0.0      0.03   \n",
       "16241  2017.0  Role-Playing          Sega      0.00       0.0      0.01   \n",
       "16438  2017.0        Action  Idea Factory      0.00       0.0      0.01   \n",
       "\n",
       "       Other_Sales  Global_Sales  \n",
       "5957          0.02          0.29  \n",
       "14390         0.00          0.03  \n",
       "16241         0.00          0.01  \n",
       "16438         0.00          0.01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify any incorrect entries for the Year\n",
    "raw[raw[\"Year\"] > 2016]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After researching, it was found that these games were released on the specified consoles in the years 2009, 2016, 2013 and 2016 respectively. These are updated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All years are up to date!\n"
     ]
    }
   ],
   "source": [
    "# Updating the Year with the correct values\n",
    "updates = {5957:2009, 14390:2016, 16241:2013, 16438:2016}\n",
    "for i in updates.keys():\n",
    "    raw.iloc[i,3] = updates[i]\n",
    "    \n",
    "if raw[raw[\"Year\"] > 2016].any().sum() == 0:\n",
    "    print(\"All years are up to date!\")\n",
    "else:\n",
    "    print(\"There are still incorrect entries.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with the next part of the task, we will determine if any outliers exist in the data. To do this we will examine some summary statistics of the numeric sales features that are in the data set. An alternative way to do this would be to make either box plots or histograms. However, this will not be done here due to the nature of the dataset. It appears a large percentage of the video games didn't have sales greater than 1 million, hence the figures will not be the most informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264667</td>\n",
       "      <td>0.146652</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>0.537441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.816683</td>\n",
       "      <td>0.505351</td>\n",
       "      <td>0.309291</td>\n",
       "      <td>0.188588</td>\n",
       "      <td>1.555028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.490000</td>\n",
       "      <td>29.020000</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.570000</td>\n",
       "      <td>82.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NA_Sales      EU_Sales      JP_Sales   Other_Sales  Global_Sales\n",
       "count  16598.000000  16598.000000  16598.000000  16598.000000  16598.000000\n",
       "mean       0.264667      0.146652      0.077782      0.048063      0.537441\n",
       "std        0.816683      0.505351      0.309291      0.188588      1.555028\n",
       "min        0.000000      0.000000      0.000000      0.000000      0.010000\n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.060000\n",
       "50%        0.080000      0.020000      0.000000      0.010000      0.170000\n",
       "75%        0.240000      0.110000      0.040000      0.040000      0.470000\n",
       "max       41.490000     29.020000     10.220000     10.570000     82.740000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of the numeric sales features\n",
    "numeric_sales_features = [\"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"Global_Sales\"]\n",
    "sales_data = raw[numeric_sales_features]\n",
    "sales_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the mean and standard deviation values, it looks as though all of the max values for the sales could be outliers. However, the max value for NA_Sales, EU_Sale and Global_sales is Wii Sports which is ranked the most popular game in the dataset. Since this is the most popular game in the dataset, by a significant amount, this will not be removed from the data. The max for JP_Sales is Pokemon Red/Pokemon Blue which were the first ever games released in a hugely popular franchise. Again, this will not be ignored. Finally, the game with the max sales for Other_Sales is Grand Theft Auto: San Andreas which is also part of another popular franchise. This will not be removed from the dataset either.\n",
    "\n",
    "It is always possible that other outliers lie within the dataset but, as mentioned, due to the nature of the dataset it is difficult to produce any meaningful visualisations to search for these. Other methods such as converting values to z scores could be considered, however since the dataset is fairly small we will stop the search for outliers and conclude that there aren't any in the data.\n",
    "\n",
    "The next task is to search for any missing values in the data, this is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank              0\n",
       "Name              0\n",
       "Platform          0\n",
       "Year            271\n",
       "Genre             0\n",
       "Publisher        58\n",
       "NA_Sales          0\n",
       "EU_Sales          0\n",
       "JP_Sales          0\n",
       "Other_Sales       0\n",
       "Global_Sales      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for where the missing values are\n",
    "raw.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there are missing values for both the Year and Publisher features. Year has 271 missing values whilst Publisher has 58. In the step below, all missing values for the Year feature are imputed using the median year value. The median is chosen as this is a more robust metric of location than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values for the Year feature.\n"
     ]
    }
   ],
   "source": [
    "# Imputing the missing Year values with the median year\n",
    "year_median = raw[\"Year\"].median(skipna=True)\n",
    "raw[\"Year\"] = raw[\"Year\"].fillna(year_median)\n",
    "missing_vals_year = raw[\"Year\"].isnull().sum()\n",
    "\n",
    "print(f\"There are {missing_vals_year} missing values for the Year feature.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year is now correct for each video game and there are no longer any missing values for this feature. Next the missing values for the Publisher feature will be updated. Only a small percentage of values are missing for this feature, also this feature will not play much of a role within the analysis being completed. For these reasons, any missing values will be imputed with the value \"Unknown\". An alternative to this would be to remove the rows containing missing values. However, imputing the missing values with \"Unknown\" means we get to keep more data and can perform a more granular analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values for the Publisher feature.\n"
     ]
    }
   ],
   "source": [
    "# Impute \"Unknown\" for missing values in the Publisher feature\n",
    "raw['Publisher'] = raw['Publisher'].fillna('Unknown')\n",
    "missing_vals_publisher = raw[\"Publisher\"].isnull().sum()\n",
    "\n",
    "print(f\"There are {missing_vals_publisher} missing values for the Publisher feature.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All missing values have now been updated and the data is complete. \n",
    "\n",
    "Finally we investigate each data type and update any which are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16598 entries, 0 to 16597\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Rank          16598 non-null  int64  \n",
      " 1   Name          16598 non-null  object \n",
      " 2   Platform      16598 non-null  object \n",
      " 3   Year          16598 non-null  float64\n",
      " 4   Genre         16598 non-null  object \n",
      " 5   Publisher     16598 non-null  object \n",
      " 6   NA_Sales      16598 non-null  float64\n",
      " 7   EU_Sales      16598 non-null  float64\n",
      " 8   JP_Sales      16598 non-null  float64\n",
      " 9   Other_Sales   16598 non-null  float64\n",
      " 10  Global_Sales  16598 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking data types\n",
    "raw.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only type which looks wrong is the Year feature. This is turned into an integer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16598 entries, 0 to 16597\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Rank          16598 non-null  int64  \n",
      " 1   Name          16598 non-null  object \n",
      " 2   Platform      16598 non-null  object \n",
      " 3   Year          16598 non-null  int64  \n",
      " 4   Genre         16598 non-null  object \n",
      " 5   Publisher     16598 non-null  object \n",
      " 6   NA_Sales      16598 non-null  float64\n",
      " 7   EU_Sales      16598 non-null  float64\n",
      " 8   JP_Sales      16598 non-null  float64\n",
      " 9   Other_Sales   16598 non-null  float64\n",
      " 10  Global_Sales  16598 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Change Year to an integer value instead of a decimal\n",
    "raw['Year'] = raw['Year'].astype('int')\n",
    "raw.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has now been updated and the data preprocessing is complete. The processed data will be saved into the data folder of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data to the data file\n",
    "raw.to_csv(\"../data/processed/vgsales_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
